{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.automobile.tn/fr/occasion'\n",
    "nbre_page=2\n",
    "n=1 #page 1\n",
    "total_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads=[]\n",
    "years=[]\n",
    "boites=[]\n",
    "transmissions=[]\n",
    "horsepowers=[]\n",
    "fuels=[]\n",
    "nbre_portes=[]\n",
    "cylindres=[]\n",
    "items = []\n",
    "marques = []\n",
    "modeles = []\n",
    "prices = []\n",
    "links = []\n",
    "features_tot=[]\n",
    "features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for n in range(nbre_page):\n",
    "    url = f'https://www.automobile.tn/fr/occasion/{n}'\n",
    "    code_page = requests.get(url)\n",
    "    soup = BeautifulSoup(code_page.text, 'html.parser')\n",
    "    \n",
    "    print(f\"Scraping URL: {url}\")\n",
    "\n",
    "    container = soup.findAll(class_='occasion-item-v2')\n",
    "\n",
    "    for item in container:\n",
    "        # Extraire les caractéristiques avec gestion des valeurs manquantes\n",
    "        road = item.find('li', class_='road')\n",
    "        if road:\n",
    "            road_text = road.text.strip()\n",
    "            # Utiliser une expression régulière pour extraire uniquement les chiffres et les espaces\n",
    "            road_nbre = re.search(r'[\\d\\s]+', road_text)\n",
    "            if road_nbre:\n",
    "                roads.append(road_nbre.group().strip())\n",
    "            else:\n",
    "                roads.append(np.nan)\n",
    "        else:\n",
    "            roads.append(np.nan)\n",
    "        print(roads)\n",
    "        year = item.find('li', class_='year')\n",
    "        years.append(year.text.strip() if year else np.nan)\n",
    "\n",
    "        boite = item.find('li', class_='boite')\n",
    "        boites.append(boite.text.strip() if boite else np.nan)\n",
    "\n",
    "        transmission = item.find('li', class_='transmission')\n",
    "        transmissions.append(transmission.text.strip() if transmission else np.nan)\n",
    "\n",
    "        horsepower = item.find('li', class_='horsepower')\n",
    "        horsepowers.append(horsepower.text.strip() if horsepower else np.nan)\n",
    "\n",
    "        fuel = item.find('li', class_='fuel')\n",
    "        fuels.append(fuel.text.strip() if fuel else np.nan)\n",
    "\n",
    "        # Extraire la marque et le modèle\n",
    "        noms = item.findAll('h2')\n",
    "        for nom in noms:\n",
    "            nom_car = nom.text.strip() if nom else np.nan\n",
    "            if nom_car:\n",
    "                marques.append(nom_car.split()[0])\n",
    "                parts = nom_car.split()\n",
    "                modeles.append(' '.join(parts[1:]))\n",
    "            else:\n",
    "                marques.append(np.nan)\n",
    "                modeles.append(np.nan)\n",
    "\n",
    "        # Extraire le prix\n",
    "        price_tag = item.find('div', class_='price')\n",
    "        price_final = price_tag.text.replace('DT', '').replace('\\xa0', '').strip() if price_tag else np.nan\n",
    "        prices.append(price_final)\n",
    "\n",
    "        # Extraire le lien\n",
    "        link_tag = item.find('a', class_='occasion-link-overlay', href=True)\n",
    "        if link_tag:\n",
    "            correct_link = f'https://www.automobile.tn/{link_tag[\"href\"]}'\n",
    "            links.append(correct_link)\n",
    "\n",
    "    # Parcourir chaque lien pour les caractéristiques supplémentaires\n",
    "    for link in links:\n",
    "        page = requests.get(link)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        container_a = soup.findAll('span', class_='spec-name')\n",
    "\n",
    "        porte, cylindre = np.nan, np.nan\n",
    "        for item in container_a:\n",
    "            # Nombre de portes\n",
    "            if item.text.strip() == 'Nombre de portes':\n",
    "                porte = item.findNext('span').text.strip() if item.findNext('span') else np.nan\n",
    "                nbre_portes.append(porte)\n",
    "\n",
    "            # Cylindrée\n",
    "            if item.text.strip() == 'Cylindrée':\n",
    "                cylindre_text = item.findNext('span').text if item.findNext('span') else np.nan\n",
    "                cylindre_number = re.search(r'\\d+', cylindre_text).group() if cylindre_text else np.nan\n",
    "                cylindres.append(cylindre_number)\n",
    "\n",
    "        # Ajouter des valeurs manquantes si non trouvées\n",
    "        if porte is np.nan:\n",
    "            nbre_portes.append(np.nan)\n",
    "        if cylindre is np.nan:\n",
    "            cylindres.append(np.nan)\n",
    "\n",
    "    # Vérification et création du DataFrame\n",
    "    if len(prices) == len(marques) == len(modeles) == len(years) == len(boites) == len(transmissions) == len(horsepowers) == len(fuels) == len(nbre_portes) == len(cylindres):\n",
    "        data = {\n",
    "            'Marque': marques,\n",
    "            'Modèle': modeles,\n",
    "            'year': years,\n",
    "            'road': roads,\n",
    "            'boite': boites,\n",
    "            'horsepower': horsepowers,\n",
    "            'fuel': fuels,\n",
    "            'nbre_portes': nbre_portes,\n",
    "            'cylindrée': cylindres,\n",
    "            'transmission': transmissions,\n",
    "            'Prix': prices\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df)\n",
    "\n",
    "    # Ajouter au DataFrame final\n",
    "    total_df = pd.concat([total_df, df], ignore_index=True)\n",
    "\n",
    "print(total_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 48 48 48 48 48 48 118 233 48\n"
     ]
    }
   ],
   "source": [
    "print(len(prices), len(marques), len(modeles), len(years), len(boites), len(transmissions), len(horsepowers), len(fuels), len(nbre_portes), len(cylindres), len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#la dataframe totale contenant les données scrapées de toutes les pages:\n",
    "total_df.to_csv('../data/cars.csv', index=False)\n",
    "# print(total_df)\n",
    "# print(road_nbre.group())\n",
    "# print(roads)\n",
    "\n",
    "print(total_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
